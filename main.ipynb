{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T21:06:14.769735Z",
     "start_time": "2024-04-16T21:06:14.659777Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # For feature engineering\n",
    "\n",
    "# Load the input files\n",
    "x_train = pd.read_csv('datasets/x_train.csv')\n",
    "y_train = pd.read_csv('datasets/y_train.csv')\n",
    "x_test = pd.read_csv('datasets/x_test.csv')\n",
    "\n",
    "# Initialize the TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(max_features=10000)  # Set the maximum number of features to 10,000\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train = tfidf.fit_transform(x_train['text'])\n",
    "X_train = X_train.toarray()\n",
    "\n",
    "# Transform the test data\n",
    "X_test = tfidf.transform(x_test['text'])\n",
    "X_test = X_test.toarray()"
   ],
   "id": "bca9ec732e11b1fe",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T09:31:58.223219Z",
     "start_time": "2024-04-15T09:31:58.219808Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Viewing shape of input data\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "# print(np.array(X_train)) # View new feature represented data"
   ],
   "id": "6a4bc9f02e741c45",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 2)\n",
      "(2400, 1)\n",
      "(600, 2)\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T09:39:59.638207Z",
     "start_time": "2024-04-15T09:39:59.634785Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Viewing shape of processed data\n",
    "print(X_train.shape[0])\n",
    "print(y_train.shape[0])"
   ],
   "id": "73f8716f59699417",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400\n",
      "2400\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T21:06:19.486211Z",
     "start_time": "2024-04-16T21:06:19.478852Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def cost_function(theta, X, y):\n",
    "    m = len(y)\n",
    "    h = sigmoid(X @ theta) # @ = matrix multiplication\n",
    "    J = (-1 / m) * (y.T @ np.log(h) + (1 - y).T @ np.log(1 - h))\n",
    "    return J[0]\n",
    "\n",
    "def gradient_descent(theta, X, y, alpha, num_iters):\n",
    "    m = len(y)\n",
    "    J_history = np.zeros(num_iters) # J_history = history of the cost function J per iteration\n",
    "\n",
    "    for i in range(num_iters):\n",
    "        h = sigmoid(X @ theta)\n",
    "        theta = theta - (alpha / m) * (X.T @ (h - y.reshape(-1, 1)))\n",
    "        J_history[i] = cost_function(theta, X, y)\n",
    "\n",
    "    return theta, J_history"
   ],
   "id": "a1a76b16bce74484",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T21:06:25.501892Z",
     "start_time": "2024-04-16T21:06:21.383637Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train the Logistic Regression model\n",
    "theta = np.zeros((X_train.shape[1], 1))\n",
    "alpha = 0.01 # learning rate/step size\n",
    "num_iters = 400\n",
    "theta, J_history = gradient_descent(theta, X_train, y_train['is_positive_sentiment'].values, alpha, num_iters)\n",
    "\n",
    "# Generate predicted probabilities for the test set\n",
    "y_prob_test = sigmoid(X_test @ theta)\n",
    "\n",
    "# Convert probabilities to binary predictions (0 or 1)\n",
    "# y_pred_test = (y_prob_test >= 0.5).astype(int)\n",
    "# np.savetxt('yprob_test.txt', y_pred_test, fmt='%d')\n",
    "\n",
    "# Save the predicted labels\n",
    "np.savetxt('yprob_test.txt', y_prob_test)"
   ],
   "id": "d7ff54777f7cbe9b",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T21:02:10.746671Z",
     "start_time": "2024-04-16T21:02:09.724022Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cross-validation for testing the model. Currently very poor results, likely due to text input being such short snippets \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the training data\n",
    "x_train = pd.read_csv('datasets/x_train.csv')\n",
    "y_train = pd.read_csv('datasets/y_train.csv')['is_positive_sentiment'].values\n",
    "\n",
    "# Split the training set in half\n",
    "X_train, X_val, y_train, y_val = train_test_split(x_train['text'], y_train, test_size=0.5, random_state=42)\n",
    "\n",
    "# Initialize the TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(max_features=10000)\n",
    "\n",
    "# Fit and transform the training and validation data\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_val_tfidf = tfidf.transform(X_val)\n",
    "\n",
    "# Train the Logistic Regression model\n",
    "theta = np.zeros((X_train_tfidf.shape[1], 1))\n",
    "alpha = 0.01\n",
    "num_iters = 400\n",
    "theta, J_history = gradient_descent(theta, X_train_tfidf.toarray(), y_train, alpha, num_iters)\n",
    "\n",
    "# Evaluate on the validation set\n",
    "y_val_prob = sigmoid(X_val_tfidf.toarray() @ theta)\n",
    "y_val_pred = (y_val_prob >= 0.5).astype(int)\n",
    "val_accuracy = np.mean(y_val_pred == y_val)\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")"
   ],
   "id": "8ed7e975c367ac87",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.4993\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "28dd4e3a7f048d2d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
